{
  "analysis_timestamp": "2025-07-10T10:31:31.153462",
  "systems": {
    "3-Small": {
      "name": "3-Small",
      "precision_at_1": 0.45454545454545453,
      "precision_at_3": 0.42424242424242425,
      "precision_at_5": 0.46666666666666673,
      "precision_at_1_lenient": 0.8181818181818182,
      "precision_at_3_lenient": 0.696969696969697,
      "precision_at_5_lenient": 0.7424242424242425,
      "ndcg_at_1": 0.6753246753246753,
      "ndcg_at_3": 0.7194482441986666,
      "ndcg_at_5": 0.8639762885315156,
      "avg_relevance_score": 2.0851063829787235,
      "total_documents": 47,
      "evaluated_documents": 47,
      "skip_rate": 0.0
    },
    "3-Large": {
      "name": "3-Large",
      "precision_at_1": 0.36363636363636365,
      "precision_at_3": 0.5,
      "precision_at_5": 0.5151515151515151,
      "precision_at_1_lenient": 0.8181818181818182,
      "precision_at_3_lenient": 0.8484848484848485,
      "precision_at_5_lenient": 0.8272727272727273,
      "ndcg_at_1": 0.5844155844155845,
      "ndcg_at_3": 0.7307421578637477,
      "ndcg_at_5": 0.8574040183603212,
      "avg_relevance_score": 2.25531914893617,
      "total_documents": 47,
      "evaluated_documents": 47,
      "skip_rate": 0.0
    }
  },
  "comparisons": [
    {
      "metric_name": "Precision@1 (strict)",
      "system1_value": 0.45454545454545453,
      "system2_value": 0.36363636363636365,
      "difference": -0.09090909090909088,
      "percent_improvement": -19.999999999999996,
      "p_value": 0.6760811849183088,
      "is_significant": "False",
      "effect_size": -0.1297498240269205,
      "confidence_interval": [
        -0.5616115272744321,
        0.3797933454562502
      ]
    },
    {
      "metric_name": "Precision@3 (strict)",
      "system1_value": 0.42424242424242425,
      "system2_value": 0.5,
      "difference": 0.07575757575757575,
      "percent_improvement": 17.857142857142854,
      "p_value": 0.5833044208393654,
      "is_significant": "False",
      "effect_size": 0.1709164497975678,
      "confidence_interval": [
        -0.22201734272735654,
        0.373532494242508
      ]
    },
    {
      "metric_name": "Precision@5 (strict)",
      "system1_value": 0.46666666666666673,
      "system2_value": 0.5151515151515151,
      "difference": 0.04848484848484841,
      "percent_improvement": 10.389610389610372,
      "p_value": 0.6071902385121198,
      "is_significant": "False",
      "effect_size": 0.16002120421443064,
      "confidence_interval": [
        -0.15506670319778587,
        0.2520364001674828
      ]
    },
    {
      "metric_name": "Precision@1 (lenient)",
      "system1_value": 0.8181818181818182,
      "system2_value": 0.8181818181818182,
      "difference": 0.0,
      "percent_improvement": 0.0,
      "p_value": 1.0,
      "is_significant": "False",
      "effect_size": 0.0,
      "confidence_interval": [
        -0.4248894077986384,
        0.4248894077986384
      ]
    },
    {
      "metric_name": "Precision@3 (lenient)",
      "system1_value": 0.696969696969697,
      "system2_value": 0.8484848484848485,
      "difference": 0.1515151515151515,
      "percent_improvement": 21.739130434782602,
      "p_value": 0.09590640413029856,
      "is_significant": "False",
      "effect_size": 0.5541888731518407,
      "confidence_interval": [
        -0.032157362935568284,
        0.33518766596587124
      ]
    },
    {
      "metric_name": "Precision@5 (lenient)",
      "system1_value": 0.7424242424242425,
      "system2_value": 0.8272727272727273,
      "difference": 0.08484848484848473,
      "percent_improvement": 11.42857142857141,
      "p_value": 0.15625054334653435,
      "is_significant": "False",
      "effect_size": 0.462254573021728,
      "confidence_interval": [
        -0.038464492592346244,
        0.2081614622893159
      ]
    },
    {
      "metric_name": "NDCG@1",
      "system1_value": 0.6753246753246753,
      "system2_value": 0.5844155844155845,
      "difference": -0.09090909090909083,
      "percent_improvement": -13.46153846153845,
      "p_value": 0.6338155278195834,
      "is_significant": "False",
      "effect_size": -0.14813363449166972,
      "confidence_interval": [
        -0.5031959999356849,
        0.321377818117503
      ]
    },
    {
      "metric_name": "NDCG@3",
      "system1_value": 0.7194482441986666,
      "system2_value": 0.7307421578637477,
      "difference": 0.011293913665081146,
      "percent_improvement": 1.569802102673903,
      "p_value": 0.9194217458538656,
      "is_significant": "False",
      "effect_size": 0.03128073563648291,
      "confidence_interval": [
        -0.23126286402289756,
        0.25385069135305977
      ]
    },
    {
      "metric_name": "NDCG@5",
      "system1_value": 0.8639762885315156,
      "system2_value": 0.8574040183603212,
      "difference": -0.006572270171194439,
      "percent_improvement": -0.7607002944913227,
      "p_value": 0.9220475236126086,
      "is_significant": "False",
      "effect_size": -0.03025756630568042,
      "confidence_interval": [
        -0.1524964709012828,
        0.13935193055889408
      ]
    },
    {
      "metric_name": "Average Relevance",
      "system1_value": 2.090909090909091,
      "system2_value": 2.283333333333333,
      "difference": 0.1924242424242424,
      "percent_improvement": 9.202898550724637,
      "p_value": 0.17090633886396875,
      "is_significant": "False",
      "effect_size": 0.4448223015568278,
      "confidence_interval": [
        -0.09819150365980397,
        0.4830399885082888
      ]
    }
  ],
  "query_analysis": {
    "qGF8pzUgIJe4cH834nOs": {
      "precision_at_5": {
        "3-Small": 0.4,
        "3-Large": 0.6,
        "difference": 0.19999999999999996
      },
      "avg_relevance": {
        "3-Small": 2.4,
        "3-Large": 2.6,
        "difference": 0.20000000000000018
      },
      "winner": "3-Large"
    },
    "GAsQmuMh3czMdqTsbY6M": {
      "precision_at_5": {
        "3-Small": 0.25,
        "3-Large": 0.2,
        "difference": -0.04999999999999999
      },
      "avg_relevance": {
        "3-Small": 1.75,
        "3-Large": 2.0,
        "difference": 0.25
      },
      "winner": "3-Small"
    },
    "3MJP0knZgSkIHCyn8aIn": {
      "precision_at_5": {
        "3-Small": 0.3333333333333333,
        "3-Large": 0.5,
        "difference": 0.16666666666666669
      },
      "avg_relevance": {
        "3-Small": 2.0,
        "3-Large": 2.5,
        "difference": 0.5
      },
      "winner": "3-Large"
    },
    "P6fkhXC9rV9JfJJ3knTa": {
      "precision_at_5": {
        "3-Small": 0.6,
        "3-Large": 0.75,
        "difference": 0.15000000000000002
      },
      "avg_relevance": {
        "3-Small": 2.2,
        "3-Large": 2.75,
        "difference": 0.5499999999999998
      },
      "winner": "3-Large"
    },
    "Y5jBhOAvjHzr3Isl7B4t": {
      "precision_at_5": {
        "3-Small": 0.2,
        "3-Large": 0.6,
        "difference": 0.39999999999999997
      },
      "avg_relevance": {
        "3-Small": 1.0,
        "3-Large": 2.0,
        "difference": 1.0
      },
      "winner": "3-Large"
    },
    "sQzUsmG3BUPYH0hnEzX9": {
      "precision_at_5": {
        "3-Small": 0.8,
        "3-Large": 0.6,
        "difference": -0.20000000000000007
      },
      "avg_relevance": {
        "3-Small": 2.8,
        "3-Large": 2.6,
        "difference": -0.19999999999999973
      },
      "winner": "3-Small"
    },
    "5qBnoncWrJoWlcDIUKq2": {
      "precision_at_5": {
        "3-Small": 0.6,
        "3-Large": 0.6,
        "difference": 0.0
      },
      "avg_relevance": {
        "3-Small": 2.0,
        "3-Large": 2.0,
        "difference": 0.0
      },
      "winner": "tie"
    },
    "ANUvcvQObotGp9NiIawq": {
      "precision_at_5": {
        "3-Small": 0.2,
        "3-Large": 0.4,
        "difference": 0.2
      },
      "avg_relevance": {
        "3-Small": 1.6,
        "3-Large": 2.0,
        "difference": 0.3999999999999999
      },
      "winner": "3-Large"
    },
    "fMCgfVG2mJFA48kDrHgo": {
      "precision_at_5": {
        "3-Small": 0.0,
        "3-Large": 0.5,
        "difference": 0.5
      },
      "avg_relevance": {
        "3-Small": 2.0,
        "3-Large": 2.25,
        "difference": 0.25
      },
      "winner": "3-Large"
    },
    "FDNqJL6kGszttSS4kVFy": {
      "precision_at_5": {
        "3-Small": 1.0,
        "3-Large": 0.6666666666666666,
        "difference": -0.33333333333333337
      },
      "avg_relevance": {
        "3-Small": 3.0,
        "3-Large": 2.6666666666666665,
        "difference": -0.3333333333333335
      },
      "winner": "3-Small"
    },
    "JGNqNXdGGu5SiA0b5DDj": {
      "precision_at_5": {
        "3-Small": 0.75,
        "3-Large": 0.25,
        "difference": -0.5
      },
      "avg_relevance": {
        "3-Small": 2.25,
        "3-Large": 1.75,
        "difference": -0.5
      },
      "winner": "3-Small"
    }
  },
  "summary_stats": {
    "total_queries": 11,
    "system1_wins": 4,
    "system2_wins": 6,
    "ties": 1
  }
}